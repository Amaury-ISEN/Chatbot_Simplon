{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "weird-jewel",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "\n",
    "Options :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "under-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = True\n",
    "#train_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "objective-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = False\n",
    "#api = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "underlying-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = False\n",
    "test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-there",
   "metadata": {},
   "source": [
    "Importer les modules nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import FrenchStemmer, EnglishStemmer\n",
    "from nltk.corpus import stopwords \n",
    "from langdetect import detect_langs\n",
    "import unicodedata\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense,GlobalMaxPooling1D,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-petersburg",
   "metadata": {},
   "source": [
    "Obtenir la DataFrame à partir de ``content.json`` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "entertaining-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouvrir le fichier JSON\n",
    "from connecteur import Connecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "derived-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = Connecteur.get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "critical-sampling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Y a-t-il des examens pendant la formation ?</td>\n",
       "      <td>evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Examens</td>\n",
       "      <td>evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>What do I have to do to complete the program?</td>\n",
       "      <td>en_evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>What teachers will the students have?</td>\n",
       "      <td>en_enseignants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Hi, how are you ?</td>\n",
       "      <td>en_salutation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>I am looking for training</td>\n",
       "      <td>en_apprenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Diplôme ?</td>\n",
       "      <td>titre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>What jobs are we being trained for?</td>\n",
       "      <td>en_debouches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Quel niveau d'étude est demandé ?</td>\n",
       "      <td>admission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Quels débouchés pour les élèves ?</td>\n",
       "      <td>debouches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             inputs            tags\n",
       "422     Y a-t-il des examens pendant la formation ?     evaluation \n",
       "430                                         Examens     evaluation \n",
       "998   What do I have to do to complete the program?   en_evaluation\n",
       "931           What teachers will the students have?  en_enseignants\n",
       "686                               Hi, how are you ?   en_salutation\n",
       "...                                             ...             ...\n",
       "603                       I am looking for training    en_apprenant\n",
       "333                                       Diplôme ?           titre\n",
       "1014            What jobs are we being trained for?    en_debouches\n",
       "203               Quel niveau d'étude est demandé ?       admission\n",
       "472               Quels débouchés pour les élèves ?       debouches\n",
       "\n",
       "[1057 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "apprenant             53\n",
       "debouches             47\n",
       "admission             42\n",
       "en_covid              41\n",
       "partenaire            38\n",
       "en_aide financiere    37\n",
       "covid                 36\n",
       "en_apprenant          36\n",
       "en_negation           35\n",
       "alternance            33\n",
       "en_salutation         32\n",
       "en_partner            32\n",
       "en_titre              32\n",
       "pédagogie             31\n",
       "en_affirmation        31\n",
       "en_admission          31\n",
       "evaluation            31\n",
       "code                  31\n",
       "enseignants           30\n",
       "en_evaluation         30\n",
       "en_alternance         29\n",
       "en_pédagogie          28\n",
       "titre                 27\n",
       "salutation            27\n",
       "en_debouches          27\n",
       "fin                   26\n",
       "en_fin                25\n",
       "affirmation           24\n",
       "date                  23\n",
       "en_code               23\n",
       "en_date               22\n",
       "en_enseignants        20\n",
       "negation              20\n",
       "en_insultes           16\n",
       "aide financiere        6\n",
       "insultes               5\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#créer les listes vides\n",
    "tags = []\n",
    "inputs = []\n",
    "responses={}\n",
    "#les remplir avec le contenu du JSON\n",
    "for intent in data1['intents']:\n",
    "  responses[intent['tag']]=intent['liste_output']\n",
    "  for lines in intent['liste_input']:\n",
    "    inputs.append(lines)\n",
    "    tags.append(intent['tag'])\n",
    "    \n",
    "#convertir en DataFrame\n",
    "data = pd.DataFrame({\"inputs\":inputs,\n",
    "                     \"tags\":tags})\n",
    "\n",
    "#mélanger aléatoirement\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "#montrer la DataFrame\n",
    "display(data)\n",
    "#montrer les catégories\n",
    "data[\"tags\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-office",
   "metadata": {},
   "source": [
    "Créer les fonctions de traitement du texte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artistic-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enlever les accents du texte\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return str(only_ascii)[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threatened-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#définir les stopwords\n",
    "stop_words_en = list(set(stopwords.words('english')))\n",
    "stop_words_fr = list(set(stopwords.words('french')))\n",
    "\n",
    "#rajouter aux stopwords français leurs versions sans accents\n",
    "stop_words_fr_1 = []\n",
    "for word in stop_words_fr:\n",
    "    word = remove_accents(word)\n",
    "    stop_words_fr_1.append(word)\n",
    "stop_words_fr = list(sorted(set(stop_words_fr + stop_words_fr_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "future-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traiter le texte\n",
    "def treatment(text):\n",
    "    #vérifier si c'est une question\n",
    "    if text[-1] == \"?\":\n",
    "        question = \"?\"\n",
    "    else:\n",
    "        question = \"0\"\n",
    "        \n",
    "    #vérifier la langue\n",
    "    language_list = detect_langs(text)\n",
    "    language_list_2 = []\n",
    "    for language in language_list:\n",
    "        language = str(language).split(\":\")[0]\n",
    "        language_list_2.append(language)\n",
    "    if \"fr\" in language_list_2:\n",
    "        language = \"francais\"\n",
    "    elif \"en\" in language_list_2:\n",
    "        language = \"anglais\"\n",
    "    else:\n",
    "        language = \"francais\"\n",
    "    \n",
    "    #segmenter le texte et traiter chaque mot et chaque lettre\n",
    "    text = text.split()\n",
    "    words_list = []\n",
    "    for word in text:\n",
    "        letters_list = []\n",
    "        for character in word:\n",
    "            #vérifier que le caractère est une lettre\n",
    "            if character.isalpha():\n",
    "                #rajouter à la liste en minuscule\n",
    "                letters_list.append(character.lower())\n",
    "            else:\n",
    "                letters_list.append(\" \")\n",
    "        word = \"\".join(letters_list)\n",
    "        \n",
    "        #appliquer le stemming suivant la langue\n",
    "        for word1 in word.split():\n",
    "            word_yes = False\n",
    "            if language == \"anglais\":\n",
    "                if word1 not in stop_words_en:\n",
    "                    word1 = EnglishStemmer().stem(word1)\n",
    "                    word_yes = True\n",
    "            else:\n",
    "                if word1 not in stop_words_fr:\n",
    "                    word1 = FrenchStemmer().stem(word1)\n",
    "                    word_yes = True\n",
    "            #enlever les accents\n",
    "            if word_yes == True:\n",
    "                word1 = remove_accents(word1)\n",
    "                words_list.append(word1)\n",
    "            \n",
    "    #joindre en une string\n",
    "    text = \" \".join(words_list)\n",
    "    return \" \".join([text, question, language])\n",
    "    #pour avoir en trois colonnes\n",
    "    #return [text, question, language]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-hybrid",
   "metadata": {},
   "source": [
    "Obtenir une colonne avec les inputs traités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hourly-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour avoir en trois colonnes\n",
    "\n",
    "#text_list = []\n",
    "#ques_list = []\n",
    "#lang_list = []\n",
    "\n",
    "#for value in data[\"inputs\"]:\n",
    "    #value = treatment(value)\n",
    "    #text_list.append(value[0])\n",
    "    #ques_list.append(value[1])\n",
    "    #lang_list.append(value[2])\n",
    "\n",
    "#data[\"text\"] = text_list\n",
    "#data[\"?\"] = ques_list\n",
    "#data[\"language\"] = lang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "former-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"texts\"] = data[\"inputs\"].apply(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "little-seeking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Y a-t-il des examens pendant la formation ?</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>examen pend format ? francais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Examens</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>examen 0 francais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>What do I have to do to complete the program?</td>\n",
       "      <td>en_evaluation</td>\n",
       "      <td>complet program ? anglais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>What teachers will the students have?</td>\n",
       "      <td>en_enseignants</td>\n",
       "      <td>teacher student ? anglais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Hi, how are you ?</td>\n",
       "      <td>en_salutation</td>\n",
       "      <td>hi ? anglais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>I am looking for training</td>\n",
       "      <td>en_apprenant</td>\n",
       "      <td>look train 0 anglais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Diplôme ?</td>\n",
       "      <td>titre</td>\n",
       "      <td>diplom ? francais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>What jobs are we being trained for?</td>\n",
       "      <td>en_debouches</td>\n",
       "      <td>job train ? anglais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Quel niveau d'étude est demandé ?</td>\n",
       "      <td>admission</td>\n",
       "      <td>quel niveau etud demand ? francais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Quels débouchés pour les élèves ?</td>\n",
       "      <td>debouches</td>\n",
       "      <td>quel debouch elev ? francais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             inputs            tags  \\\n",
       "422     Y a-t-il des examens pendant la formation ?     evaluation    \n",
       "430                                         Examens     evaluation    \n",
       "998   What do I have to do to complete the program?   en_evaluation   \n",
       "931           What teachers will the students have?  en_enseignants   \n",
       "686                               Hi, how are you ?   en_salutation   \n",
       "...                                             ...             ...   \n",
       "603                       I am looking for training    en_apprenant   \n",
       "333                                       Diplôme ?           titre   \n",
       "1014            What jobs are we being trained for?    en_debouches   \n",
       "203               Quel niveau d'étude est demandé ?       admission   \n",
       "472               Quels débouchés pour les élèves ?       debouches   \n",
       "\n",
       "                                   texts  \n",
       "422        examen pend format ? francais  \n",
       "430                    examen 0 francais  \n",
       "998            complet program ? anglais  \n",
       "931            teacher student ? anglais  \n",
       "686                         hi ? anglais  \n",
       "...                                  ...  \n",
       "603                 look train 0 anglais  \n",
       "333                    diplom ? francais  \n",
       "1014                 job train ? anglais  \n",
       "203   quel niveau etud demand ? francais  \n",
       "472         quel debouch elev ? francais  \n",
       "\n",
       "[1057 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-albania",
   "metadata": {},
   "source": [
    "Appliquer le tokenizer sur les inputs traités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "valid-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(data['texts'])\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "train = tokenizer.texts_to_sequences(data['texts'])\n",
    "#apply padding\n",
    "x_train = pad_sequences(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reliable-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 176,   4,   1],\n",
       "       [  0,   0,   0, ..., 142,   3,   1],\n",
       "       [  0,   0,   0, ...,  29,   7,   2],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  46,  40,   2],\n",
       "       [  0,   0,   0, ..., 126, 503,   1],\n",
       "       [  0,   0,   0, ...,  67,  31,   1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-allah",
   "metadata": {},
   "source": [
    "Appliquer LabelEncoder() sur les tags :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "going-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(data['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "damaged-calvin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "clean-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots uniques :  503\n",
      "Taille des outputs :  36\n"
     ]
    }
   ],
   "source": [
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"Nombre de mots uniques : \",vocabulary)\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"Taille des outputs : \",output_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-howard",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-awareness",
   "metadata": {},
   "source": [
    "Séparer ``x_train`` et ``y_train`` en ``train`` et ``val`` pour la validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "supreme-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#longueur d'1/5 du Dataset\n",
    "prod=int(len(x_train)* 0.2)\n",
    "\n",
    "#séparation en x_val et x_train\n",
    "x_val=x_train[-prod:, :]\n",
    "x_train=x_train[:-prod, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pretty-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#séparation en y_val et y_train\n",
    "y_val=y_train[ -prod:]\n",
    "y_train=y_train[:-prod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "weighted-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(846, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(211,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(846,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_val.shape,x_train1.shape,y_val.shape,y_train1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-webcam",
   "metadata": {},
   "source": [
    "Créer et entraîner le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "useful-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.5802 - accuracy: 0.0482\n",
      "Epoch 00001: loss improved from inf to 3.58019, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.5802 - accuracy: 0.0482\n",
      "Epoch 2/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.5678 - accuracy: 0.0501\n",
      "Epoch 00002: loss improved from 3.58019 to 3.56776, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.5678 - accuracy: 0.0501\n",
      "Epoch 3/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.5422 - accuracy: 0.0501\n",
      "Epoch 00003: loss improved from 3.56776 to 3.54223, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.5422 - accuracy: 0.0501\n",
      "Epoch 4/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.4795 - accuracy: 0.0530\n",
      "Epoch 00004: loss improved from 3.54223 to 3.47946, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 3.4795 - accuracy: 0.0530\n",
      "Epoch 5/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.3103 - accuracy: 0.0880\n",
      "Epoch 00005: loss improved from 3.47946 to 3.31027, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 3.3103 - accuracy: 0.0880\n",
      "Epoch 6/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 3.0544 - accuracy: 0.1420\n",
      "Epoch 00006: loss improved from 3.31027 to 3.05410, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.0541 - accuracy: 0.1419\n",
      "Epoch 7/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 2.7676 - accuracy: 0.2348\n",
      "Epoch 00007: loss improved from 3.05410 to 2.76705, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 2.7670 - accuracy: 0.2346\n",
      "Epoch 8/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.5084 - accuracy: 0.3198\n",
      "Epoch 00008: loss improved from 2.76705 to 2.50843, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 2.5084 - accuracy: 0.3198\n",
      "Epoch 9/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 2.2958 - accuracy: 0.3942\n",
      "Epoch 00009: loss improved from 2.50843 to 2.28613, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 2.2861 - accuracy: 0.4002\n",
      "Epoch 10/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 2.1385 - accuracy: 0.4541\n",
      "Epoch 00010: loss improved from 2.28613 to 2.13189, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 2.1319 - accuracy: 0.4579\n",
      "Epoch 11/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.9859 - accuracy: 0.4919\n",
      "Epoch 00011: loss improved from 2.13189 to 1.98388, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1.9839 - accuracy: 0.4901\n",
      "Epoch 12/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.8624 - accuracy: 0.5312\n",
      "Epoch 00012: loss improved from 1.98388 to 1.86302, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1.8630 - accuracy: 0.5289\n",
      "Epoch 13/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.7607 - accuracy: 0.5736\n",
      "Epoch 00013: loss improved from 1.86302 to 1.76083, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 1.7608 - accuracy: 0.5724\n",
      "Epoch 14/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.6514 - accuracy: 0.6230\n",
      "Epoch 00014: loss improved from 1.76083 to 1.65430, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 1.6543 - accuracy: 0.6197\n",
      "Epoch 15/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.6732 - accuracy: 0.6052\n",
      "Epoch 00015: loss did not improve from 1.65430\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 1.6691 - accuracy: 0.6017\n",
      "Epoch 16/300\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 1.5315 - accuracy: 0.6433\n",
      "Epoch 00016: loss improved from 1.65430 to 1.52423, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1.5242 - accuracy: 0.6452\n",
      "Epoch 17/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.4461 - accuracy: 0.6683\n",
      "Epoch 00017: loss improved from 1.52423 to 1.44545, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 1.4454 - accuracy: 0.6708\n",
      "Epoch 18/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.4599 - accuracy: 0.6552\n",
      "Epoch 00018: loss did not improve from 1.44545\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 1.4483 - accuracy: 0.6604\n",
      "Epoch 19/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.3177 - accuracy: 0.7046\n",
      "Epoch 00019: loss improved from 1.44545 to 1.31684, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 1.3168 - accuracy: 0.7067\n",
      "Epoch 20/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.2333 - accuracy: 0.7651\n",
      "Epoch 00020: loss improved from 1.31684 to 1.24157, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 1.2416 - accuracy: 0.7597\n",
      "Epoch 21/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 1.1981 - accuracy: 0.7676\n",
      "Epoch 00021: loss improved from 1.24157 to 1.19700, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 1.1970 - accuracy: 0.7701\n",
      "Epoch 22/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.1345 - accuracy: 0.7833\n",
      "Epoch 00022: loss improved from 1.19700 to 1.13412, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1.1341 - accuracy: 0.7871\n",
      "Epoch 23/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.0875 - accuracy: 0.8010\n",
      "Epoch 00023: loss improved from 1.13412 to 1.09022, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1.0902 - accuracy: 0.8013\n",
      "Epoch 24/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 1.0400 - accuracy: 0.8125\n",
      "Epoch 00024: loss improved from 1.09022 to 1.03954, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 1.0395 - accuracy: 0.8127\n",
      "Epoch 25/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.0045 - accuracy: 0.8104\n",
      "Epoch 00025: loss improved from 1.03954 to 1.00308, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 1.0031 - accuracy: 0.8127\n",
      "Epoch 26/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.1132 - accuracy: 0.7427\n",
      "Epoch 00026: loss did not improve from 1.00308\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 1.0931 - accuracy: 0.7502\n",
      "Epoch 27/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.9377 - accuracy: 0.8296\n",
      "Epoch 00027: loss improved from 1.00308 to 0.94525, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.9452 - accuracy: 0.8278\n",
      "Epoch 28/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.9386 - accuracy: 0.8296\n",
      "Epoch 00028: loss improved from 0.94525 to 0.92874, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.9287 - accuracy: 0.8344\n",
      "Epoch 29/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.8342 - accuracy: 0.8646\n",
      "Epoch 00029: loss improved from 0.92874 to 0.84704, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.8470 - accuracy: 0.8600\n",
      "Epoch 30/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.8149 - accuracy: 0.8687\n",
      "Epoch 00030: loss improved from 0.84704 to 0.81402, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.8140 - accuracy: 0.8685\n",
      "Epoch 31/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.7798 - accuracy: 0.8781\n",
      "Epoch 00031: loss improved from 0.81402 to 0.77246, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.7725 - accuracy: 0.8789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.7527 - accuracy: 0.8770\n",
      "Epoch 00032: loss improved from 0.77246 to 0.74481, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.7448 - accuracy: 0.8808\n",
      "Epoch 33/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.7230 - accuracy: 0.8881\n",
      "Epoch 00033: loss improved from 0.74481 to 0.72867, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.7287 - accuracy: 0.8827\n",
      "Epoch 34/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.7450 - accuracy: 0.8667\n",
      "Epoch 00034: loss did not improve from 0.72867\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7459 - accuracy: 0.8638\n",
      "Epoch 35/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.6683 - accuracy: 0.8942\n",
      "Epoch 00035: loss improved from 0.72867 to 0.67662, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.6766 - accuracy: 0.8921\n",
      "Epoch 36/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.6477 - accuracy: 0.8962\n",
      "Epoch 00036: loss improved from 0.67662 to 0.65036, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.6504 - accuracy: 0.8978\n",
      "Epoch 37/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6247 - accuracy: 0.9092\n",
      "Epoch 00037: loss improved from 0.65036 to 0.62466, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.6247 - accuracy: 0.9092\n",
      "Epoch 38/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.6170 - accuracy: 0.9010\n",
      "Epoch 00038: loss improved from 0.62466 to 0.60971, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.6097 - accuracy: 0.9073\n",
      "Epoch 39/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.5758 - accuracy: 0.9153\n",
      "Epoch 00039: loss improved from 0.60971 to 0.58146, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.5815 - accuracy: 0.9139\n",
      "Epoch 40/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.7291 - accuracy: 0.8448\n",
      "Epoch 00040: loss did not improve from 0.58146\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.7165 - accuracy: 0.8505\n",
      "Epoch 41/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.5578 - accuracy: 0.9183\n",
      "Epoch 00041: loss improved from 0.58146 to 0.56277, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.5628 - accuracy: 0.9158\n",
      "Epoch 42/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.5354 - accuracy: 0.9294\n",
      "Epoch 00042: loss improved from 0.56277 to 0.52958, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.5296 - accuracy: 0.9300\n",
      "Epoch 43/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4940 - accuracy: 0.9333\n",
      "Epoch 00043: loss improved from 0.52958 to 0.50244, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.9309\n",
      "Epoch 44/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.4798 - accuracy: 0.9395\n",
      "Epoch 00044: loss improved from 0.50244 to 0.48604, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.4860 - accuracy: 0.9385\n",
      "Epoch 45/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4694 - accuracy: 0.9427\n",
      "Epoch 00045: loss improved from 0.48604 to 0.46654, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.4665 - accuracy: 0.9423\n",
      "Epoch 46/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.9461\n",
      "Epoch 00046: loss improved from 0.46654 to 0.44959, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.4496 - accuracy: 0.9461\n",
      "Epoch 47/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.9385\n",
      "Epoch 00047: loss did not improve from 0.44959\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.4645 - accuracy: 0.9385\n",
      "Epoch 48/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4540 - accuracy: 0.9375\n",
      "Epoch 00048: loss did not improve from 0.44959\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.4539 - accuracy: 0.9376\n",
      "Epoch 49/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.4237 - accuracy: 0.9415\n",
      "Epoch 00049: loss improved from 0.44959 to 0.42552, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.4255 - accuracy: 0.9423\n",
      "Epoch 50/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4508 - accuracy: 0.9354\n",
      "Epoch 00050: loss did not improve from 0.42552\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.4493 - accuracy: 0.9357\n",
      "Epoch 51/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4290 - accuracy: 0.9328\n",
      "Epoch 00051: loss did not improve from 0.42552\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.4290 - accuracy: 0.9328\n",
      "Epoch 52/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3965 - accuracy: 0.9435\n",
      "Epoch 00052: loss improved from 0.42552 to 0.39089, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.3909 - accuracy: 0.9451\n",
      "Epoch 53/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3734 - accuracy: 0.9456\n",
      "Epoch 00053: loss improved from 0.39089 to 0.37456, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.3746 - accuracy: 0.9461\n",
      "Epoch 54/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3711 - accuracy: 0.9427\n",
      "Epoch 00054: loss improved from 0.37456 to 0.37325, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.3732 - accuracy: 0.9423\n",
      "Epoch 55/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.9479 ETA: 0s - loss: 0.3513 - accuracy: 0.94\n",
      "Epoch 00055: loss improved from 0.37325 to 0.35102, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.3510 - accuracy: 0.9480\n",
      "Epoch 56/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3540 - accuracy: 0.9473\n",
      "Epoch 00056: loss did not improve from 0.35102\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.3529 - accuracy: 0.9470\n",
      "Epoch 57/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.9510\n",
      "Epoch 00057: loss improved from 0.35102 to 0.32940, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.3294 - accuracy: 0.9508\n",
      "Epoch 58/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9531\n",
      "Epoch 00058: loss improved from 0.32940 to 0.32687, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.3269 - accuracy: 0.9499\n",
      "Epoch 59/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3332 - accuracy: 0.9479\n",
      "Epoch 00059: loss improved from 0.32687 to 0.32587, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.3259 - accuracy: 0.9489\n",
      "Epoch 60/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.9536\n",
      "Epoch 00060: loss improved from 0.32587 to 0.30765, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.3077 - accuracy: 0.9536\n",
      "Epoch 61/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3054 - accuracy: 0.9541\n",
      "Epoch 00061: loss improved from 0.30765 to 0.30625, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.3063 - accuracy: 0.9536\n",
      "Epoch 62/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3053 - accuracy: 0.9496\n",
      "Epoch 00062: loss improved from 0.30625 to 0.30109, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.3011 - accuracy: 0.9508\n",
      "Epoch 63/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3009 - accuracy: 0.9510\n",
      "Epoch 00063: loss improved from 0.30109 to 0.30005, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.3001 - accuracy: 0.9527\n",
      "Epoch 64/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2907 - accuracy: 0.9541\n",
      "Epoch 00064: loss improved from 0.30005 to 0.28599, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.9555\n",
      "Epoch 65/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2781 - accuracy: 0.9607\n",
      "Epoch 00065: loss improved from 0.28599 to 0.27760, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.2776 - accuracy: 0.9593\n",
      "Epoch 66/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2708 - accuracy: 0.9597\n",
      "Epoch 00066: loss improved from 0.27760 to 0.27163, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2716 - accuracy: 0.9603\n",
      "Epoch 67/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9545\n",
      "Epoch 00067: loss improved from 0.27163 to 0.26617, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.2662 - accuracy: 0.9546\n",
      "Epoch 68/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2849 - accuracy: 0.9521\n",
      "Epoch 00068: loss did not improve from 0.26617\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2776 - accuracy: 0.9536\n",
      "Epoch 69/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3054 - accuracy: 0.9385\n",
      "Epoch 00069: loss did not improve from 0.26617\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2966 - accuracy: 0.9423\n",
      "Epoch 70/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2642 - accuracy: 0.9577\n",
      "Epoch 00070: loss improved from 0.26617 to 0.26355, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.2635 - accuracy: 0.9584\n",
      "Epoch 71/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2630 - accuracy: 0.9567\n",
      "Epoch 00071: loss improved from 0.26355 to 0.25930, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2593 - accuracy: 0.9584\n",
      "Epoch 72/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2401 - accuracy: 0.9604\n",
      "Epoch 00072: loss improved from 0.25930 to 0.24601, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.2460 - accuracy: 0.9593\n",
      "Epoch 73/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.5440 - accuracy: 0.8558\n",
      "Epoch 00073: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.5607 - accuracy: 0.8524\n",
      "Epoch 74/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.6849 - accuracy: 0.8135\n",
      "Epoch 00074: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.6497 - accuracy: 0.8259\n",
      "Epoch 75/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3905 - accuracy: 0.9277\n",
      "Epoch 00075: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.3899 - accuracy: 0.9272\n",
      "Epoch 76/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3427 - accuracy: 0.9395\n",
      "Epoch 00076: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.3443 - accuracy: 0.9376\n",
      "Epoch 77/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2998 - accuracy: 0.9502\n",
      "Epoch 00077: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2955 - accuracy: 0.9518\n",
      "Epoch 78/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2775 - accuracy: 0.9521\n",
      "Epoch 00078: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.2776 - accuracy: 0.9518\n",
      "Epoch 79/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2517 - accuracy: 0.9577\n",
      "Epoch 00079: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.2577 - accuracy: 0.9555\n",
      "Epoch 80/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2486 - accuracy: 0.9594\n",
      "Epoch 00080: loss did not improve from 0.24601\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2494 - accuracy: 0.9593\n",
      "Epoch 81/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2381 - accuracy: 0.9607\n",
      "Epoch 00081: loss improved from 0.24601 to 0.23798, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.2380 - accuracy: 0.9603\n",
      "Epoch 82/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2382 - accuracy: 0.9590\n",
      "Epoch 00082: loss did not improve from 0.23798\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2410 - accuracy: 0.9584\n",
      "Epoch 83/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.9584\n",
      "Epoch 00083: loss improved from 0.23798 to 0.22884, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2288 - accuracy: 0.9584\n",
      "Epoch 84/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2220 - accuracy: 0.9637\n",
      "Epoch 00084: loss improved from 0.22884 to 0.22308, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2231 - accuracy: 0.9640\n",
      "Epoch 85/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2199 - accuracy: 0.9625\n",
      "Epoch 00085: loss improved from 0.22308 to 0.21815, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2181 - accuracy: 0.9631\n",
      "Epoch 86/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2142 - accuracy: 0.9617\n",
      "Epoch 00086: loss improved from 0.21815 to 0.21516, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2152 - accuracy: 0.9603\n",
      "Epoch 87/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2110 - accuracy: 0.9658\n",
      "Epoch 00087: loss improved from 0.21516 to 0.20779, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.2078 - accuracy: 0.9669\n",
      "Epoch 88/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2136 - accuracy: 0.9637\n",
      "Epoch 00088: loss did not improve from 0.20779\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2107 - accuracy: 0.9640\n",
      "Epoch 89/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2016 - accuracy: 0.9688\n",
      "Epoch 00089: loss improved from 0.20779 to 0.19732, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1973 - accuracy: 0.9697\n",
      "Epoch 90/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.9669\n",
      "Epoch 00090: loss improved from 0.19732 to 0.19069, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.1907 - accuracy: 0.9669\n",
      "Epoch 91/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9659\n",
      "Epoch 00091: loss improved from 0.19069 to 0.19003, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.1900 - accuracy: 0.9659\n",
      "Epoch 92/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1841 - accuracy: 0.9688\n",
      "Epoch 00092: loss improved from 0.19003 to 0.18415, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.1841 - accuracy: 0.9688\n",
      "Epoch 93/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1843 - accuracy: 0.9667\n",
      "Epoch 00093: loss improved from 0.18415 to 0.18260, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1826 - accuracy: 0.9669\n",
      "Epoch 94/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1754 - accuracy: 0.9688\n",
      "Epoch 00094: loss improved from 0.18260 to 0.17624, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1762 - accuracy: 0.9688\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1756 - accuracy: 0.9698\n",
      "Epoch 00095: loss did not improve from 0.17624\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1791 - accuracy: 0.9659\n",
      "Epoch 96/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.9697\n",
      "Epoch 00096: loss improved from 0.17624 to 0.17294, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1729 - accuracy: 0.9697\n",
      "Epoch 97/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1685 - accuracy: 0.9667\n",
      "Epoch 00097: loss improved from 0.17294 to 0.17089, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1709 - accuracy: 0.9659\n",
      "Epoch 98/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1676 - accuracy: 0.9677\n",
      "Epoch 00098: loss improved from 0.17089 to 0.16879, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1688 - accuracy: 0.9678\n",
      "Epoch 99/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3711 - accuracy: 0.9093\n",
      "Epoch 00099: loss did not improve from 0.16879\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.3587 - accuracy: 0.9130\n",
      "Epoch 100/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2097 - accuracy: 0.9594 ETA: 0s - loss: 0.2084 - accuracy\n",
      "Epoch 00100: loss did not improve from 0.16879\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2096 - accuracy: 0.9593\n",
      "Epoch 101/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1838 - accuracy: 0.9647\n",
      "Epoch 00101: loss did not improve from 0.16879\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1858 - accuracy: 0.9640\n",
      "Epoch 102/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1741 - accuracy: 0.9617\n",
      "Epoch 00102: loss did not improve from 0.16879\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1737 - accuracy: 0.9622\n",
      "Epoch 103/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1640 - accuracy: 0.9677\n",
      "Epoch 00103: loss improved from 0.16879 to 0.16295, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1629 - accuracy: 0.9678\n",
      "Epoch 104/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1570 - accuracy: 0.9677\n",
      "Epoch 00104: loss improved from 0.16295 to 0.15488, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1549 - accuracy: 0.9678\n",
      "Epoch 105/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1538 - accuracy: 0.9637\n",
      "Epoch 00105: loss improved from 0.15488 to 0.15066, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1507 - accuracy: 0.9659\n",
      "Epoch 106/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 0.9725\n",
      "Epoch 00106: loss improved from 0.15066 to 0.14785, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.1478 - accuracy: 0.9726\n",
      "Epoch 107/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1447 - accuracy: 0.9719\n",
      "Epoch 00107: loss improved from 0.14785 to 0.14346, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1435 - accuracy: 0.9716\n",
      "Epoch 108/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1436 - accuracy: 0.9708 ETA: 0s - loss: 0.1420 - accuracy\n",
      "Epoch 00108: loss improved from 0.14346 to 0.14238, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.1424 - accuracy: 0.9716\n",
      "Epoch 109/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1314 - accuracy: 0.9758\n",
      "Epoch 00109: loss improved from 0.14238 to 0.13874, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9735\n",
      "Epoch 110/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1360 - accuracy: 0.9740\n",
      "Epoch 00110: loss improved from 0.13874 to 0.13690, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1369 - accuracy: 0.9726\n",
      "Epoch 111/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9716\n",
      "Epoch 00111: loss improved from 0.13690 to 0.13408, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1341 - accuracy: 0.9716\n",
      "Epoch 112/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1367 - accuracy: 0.9717\n",
      "Epoch 00112: loss did not improve from 0.13408\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1357 - accuracy: 0.9716\n",
      "Epoch 113/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.9617\n",
      "Epoch 00113: loss did not improve from 0.13408\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.1705 - accuracy: 0.9622\n",
      "Epoch 114/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1503 - accuracy: 0.9667\n",
      "Epoch 00114: loss did not improve from 0.13408\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1579 - accuracy: 0.9650\n",
      "Epoch 115/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1536 - accuracy: 0.9627\n",
      "Epoch 00115: loss did not improve from 0.13408\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1498 - accuracy: 0.9650\n",
      "Epoch 116/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1436 - accuracy: 0.9688\n",
      "Epoch 00116: loss did not improve from 0.13408\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1430 - accuracy: 0.9688\n",
      "Epoch 117/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1514 - accuracy: 0.9657\n",
      "Epoch 00117: loss did not improve from 0.13408\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1459 - accuracy: 0.9678\n",
      "Epoch 118/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1349 - accuracy: 0.9707\n",
      "Epoch 00118: loss did not improve from 0.13408\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1368 - accuracy: 0.9697\n",
      "Epoch 119/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1330 - accuracy: 0.9708\n",
      "Epoch 00119: loss improved from 0.13408 to 0.13058, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.1306 - accuracy: 0.9716\n",
      "Epoch 120/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1236 - accuracy: 0.9708\n",
      "Epoch 00120: loss improved from 0.13058 to 0.12487, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1249 - accuracy: 0.9716\n",
      "Epoch 121/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9697 ETA: 0s - loss: 0.1038 - accuracy: 0.98 - ETA: 0s - loss: 0.1169 - accuracy: \n",
      "Epoch 00121: loss did not improve from 0.12487\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1370 - accuracy: 0.9697\n",
      "Epoch 122/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1397 - accuracy: 0.9677\n",
      "Epoch 00122: loss did not improve from 0.12487\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1372 - accuracy: 0.9697\n",
      "Epoch 123/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1356 - accuracy: 0.9656\n",
      "Epoch 00123: loss did not improve from 0.12487\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1305 - accuracy: 0.9678\n",
      "Epoch 124/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1183 - accuracy: 0.9748\n",
      "Epoch 00124: loss improved from 0.12487 to 0.11937, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1194 - accuracy: 0.9735\n",
      "Epoch 125/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1171 - accuracy: 0.9758\n",
      "Epoch 00125: loss did not improve from 0.11937\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1195 - accuracy: 0.9754\n",
      "Epoch 126/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9726\n",
      "Epoch 00126: loss improved from 0.11937 to 0.11892, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1189 - accuracy: 0.9726\n",
      "Epoch 127/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1144 - accuracy: 0.9740\n",
      "Epoch 00127: loss improved from 0.11892 to 0.11661, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1166 - accuracy: 0.9726\n",
      "Epoch 128/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1161 - accuracy: 0.9738\n",
      "Epoch 00128: loss improved from 0.11661 to 0.11329, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1133 - accuracy: 0.9745\n",
      "Epoch 129/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1121 - accuracy: 0.9718\n",
      "Epoch 00129: loss improved from 0.11329 to 0.11014, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1101 - accuracy: 0.9726\n",
      "Epoch 130/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9745\n",
      "Epoch 00130: loss improved from 0.11014 to 0.10905, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1091 - accuracy: 0.9745\n",
      "Epoch 131/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1095 - accuracy: 0.9740\n",
      "Epoch 00131: loss did not improve from 0.10905\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1129 - accuracy: 0.9726\n",
      "Epoch 132/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1067 - accuracy: 0.9746\n",
      "Epoch 00132: loss improved from 0.10905 to 0.10572, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1057 - accuracy: 0.9754\n",
      "Epoch 133/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1075 - accuracy: 0.9750\n",
      "Epoch 00133: loss did not improve from 0.10572\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1074 - accuracy: 0.9754\n",
      "Epoch 134/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1021 - accuracy: 0.9788\n",
      "Epoch 00134: loss improved from 0.10572 to 0.10450, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1045 - accuracy: 0.9773\n",
      "Epoch 135/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1056 - accuracy: 0.9729\n",
      "Epoch 00135: loss did not improve from 0.10450\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1090 - accuracy: 0.9735\n",
      "Epoch 136/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.98 - ETA: 0s - loss: 0.1009 - accuracy: 0.9782\n",
      "Epoch 00136: loss improved from 0.10450 to 0.10085, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1009 - accuracy: 0.9782\n",
      "Epoch 137/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3062 - accuracy: 0.9022\n",
      "Epoch 00137: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.3057 - accuracy: 0.9044\n",
      "Epoch 138/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1447 - accuracy: 0.9677\n",
      "Epoch 00138: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1460 - accuracy: 0.9669\n",
      "Epoch 139/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1659 - accuracy: 0.9551\n",
      "Epoch 00139: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1669 - accuracy: 0.9555\n",
      "Epoch 140/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.4233 - accuracy: 0.8623\n",
      "Epoch 00140: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.4140 - accuracy: 0.8657\n",
      "Epoch 141/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9290\n",
      "Epoch 00141: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2646 - accuracy: 0.9290\n",
      "Epoch 142/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1617 - accuracy: 0.9561\n",
      "Epoch 00142: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1610 - accuracy: 0.9555\n",
      "Epoch 143/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1184 - accuracy: 0.9728\n",
      "Epoch 00143: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1198 - accuracy: 0.9726\n",
      "Epoch 144/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9754\n",
      "Epoch 00144: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1060 - accuracy: 0.9754\n",
      "Epoch 145/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1055 - accuracy: 0.9738\n",
      "Epoch 00145: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1053 - accuracy: 0.9735\n",
      "Epoch 146/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9233\n",
      "Epoch 00146: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.2715 - accuracy: 0.9234\n",
      "Epoch 147/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9688\n",
      "Epoch 00147: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.1229 - accuracy: 0.9688\n",
      "Epoch 148/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1145 - accuracy: 0.9708\n",
      "Epoch 00148: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1143 - accuracy: 0.9697\n",
      "Epoch 149/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1296 - accuracy: 0.9648\n",
      "Epoch 00149: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1277 - accuracy: 0.9659\n",
      "Epoch 150/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1037 - accuracy: 0.9766\n",
      "Epoch 00150: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1069 - accuracy: 0.9754\n",
      "Epoch 151/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1063 - accuracy: 0.9698\n",
      "Epoch 00151: loss did not improve from 0.10085\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1043 - accuracy: 0.9707\n",
      "Epoch 152/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9735\n",
      "Epoch 00152: loss improved from 0.10085 to 0.09908, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0991 - accuracy: 0.9735\n",
      "Epoch 153/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9773\n",
      "Epoch 00153: loss improved from 0.09908 to 0.09050, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0905 - accuracy: 0.9773\n",
      "Epoch 154/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9782\n",
      "Epoch 00154: loss improved from 0.09050 to 0.08848, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0885 - accuracy: 0.9782\n",
      "Epoch 155/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0853 - accuracy: 0.9798\n",
      "Epoch 00155: loss improved from 0.08848 to 0.08759, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0876 - accuracy: 0.9782\n",
      "Epoch 156/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0971 - accuracy: 0.9748\n",
      "Epoch 00156: loss did not improve from 0.08759\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0938 - accuracy: 0.9763\n",
      "Epoch 157/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0834 - accuracy: 0.9798\n",
      "Epoch 00157: loss did not improve from 0.08759\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0878 - accuracy: 0.9773\n",
      "Epoch 158/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0824 - accuracy: 0.9802\n",
      "Epoch 00158: loss improved from 0.08759 to 0.08516, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0852 - accuracy: 0.9792\n",
      "Epoch 159/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0804 - accuracy: 0.9824\n",
      "Epoch 00159: loss improved from 0.08516 to 0.07995, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0799 - accuracy: 0.9830\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0780 - accuracy: 0.9829\n",
      "Epoch 00160: loss improved from 0.07995 to 0.07950, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0795 - accuracy: 0.9811\n",
      "Epoch 161/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0804 - accuracy: 0.9808\n",
      "Epoch 00161: loss improved from 0.07950 to 0.07826, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0783 - accuracy: 0.9820\n",
      "Epoch 162/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0799 - accuracy: 0.9802\n",
      "Epoch 00162: loss did not improve from 0.07826\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0785 - accuracy: 0.9801\n",
      "Epoch 163/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0760 - accuracy: 0.9819\n",
      "Epoch 00163: loss improved from 0.07826 to 0.07571, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0757 - accuracy: 0.9820\n",
      "Epoch 164/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9830\n",
      "Epoch 00164: loss did not improve from 0.07571\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0758 - accuracy: 0.9830\n",
      "Epoch 165/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9830\n",
      "Epoch 00165: loss improved from 0.07571 to 0.07551, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0755 - accuracy: 0.9830\n",
      "Epoch 166/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0770 - accuracy: 0.9819\n",
      "Epoch 00166: loss did not improve from 0.07551\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.9811\n",
      "Epoch 167/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0736 - accuracy: 0.9839\n",
      "Epoch 00167: loss improved from 0.07551 to 0.07362, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0736 - accuracy: 0.9839\n",
      "Epoch 168/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0753 - accuracy: 0.9812\n",
      "Epoch 00168: loss did not improve from 0.07362\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0737 - accuracy: 0.9811\n",
      "Epoch 169/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0696 - accuracy: 0.9844\n",
      "Epoch 00169: loss did not improve from 0.07362\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0744 - accuracy: 0.9830\n",
      "Epoch 170/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0774 - accuracy: 0.9839\n",
      "Epoch 00170: loss did not improve from 0.07362\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0753 - accuracy: 0.9839\n",
      "Epoch 171/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9801\n",
      "Epoch 00171: loss did not improve from 0.07362\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0741 - accuracy: 0.9801\n",
      "Epoch 172/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0749 - accuracy: 0.9823\n",
      "Epoch 00172: loss did not improve from 0.07362\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0779 - accuracy: 0.9811\n",
      "Epoch 173/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0894 - accuracy: 0.9768\n",
      "Epoch 00173: loss did not improve from 0.07362\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0863 - accuracy: 0.9782\n",
      "Epoch 174/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0774 - accuracy: 0.9812\n",
      "Epoch 00174: loss did not improve from 0.07362\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0784 - accuracy: 0.9811\n",
      "Epoch 175/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0733 - accuracy: 0.9823\n",
      "Epoch 00175: loss improved from 0.07362 to 0.07278, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0728 - accuracy: 0.9830\n",
      "Epoch 176/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0713 - accuracy: 0.9819\n",
      "Epoch 00176: loss improved from 0.07278 to 0.06917, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0692 - accuracy: 0.9830\n",
      "Epoch 177/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9830\n",
      "Epoch 00177: loss improved from 0.06917 to 0.06875, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0688 - accuracy: 0.9830\n",
      "Epoch 178/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0719 - accuracy: 0.9805\n",
      "Epoch 00178: loss did not improve from 0.06875\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0703 - accuracy: 0.9811\n",
      "Epoch 179/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0657 - accuracy: 0.9854\n",
      "Epoch 00179: loss improved from 0.06875 to 0.06749, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0675 - accuracy: 0.9849\n",
      "Epoch 180/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9830\n",
      "Epoch 00180: loss improved from 0.06749 to 0.06577, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0658 - accuracy: 0.9830\n",
      "Epoch 181/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9839\n",
      "Epoch 00181: loss did not improve from 0.06577\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9839\n",
      "Epoch 182/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9839\n",
      "Epoch 00182: loss did not improve from 0.06577\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0663 - accuracy: 0.9839\n",
      "Epoch 183/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0666 - accuracy: 0.9839\n",
      "Epoch 00183: loss did not improve from 0.06577\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0670 - accuracy: 0.9839\n",
      "Epoch 184/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0649 - accuracy: 0.9839\n",
      "Epoch 00184: loss improved from 0.06577 to 0.06486, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0649 - accuracy: 0.9839\n",
      "Epoch 185/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0636 - accuracy: 0.9839\n",
      "Epoch 00185: loss improved from 0.06486 to 0.06390, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.0639 - accuracy: 0.9830\n",
      "Epoch 186/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0697 - accuracy: 0.9833\n",
      "Epoch 00186: loss did not improve from 0.06390\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0680 - accuracy: 0.9839\n",
      "Epoch 187/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0665 - accuracy: 0.9839\n",
      "Epoch 00187: loss did not improve from 0.06390\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0657 - accuracy: 0.9839\n",
      "Epoch 188/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0617 - accuracy: 0.9849\n",
      "Epoch 00188: loss improved from 0.06390 to 0.06348, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0635 - accuracy: 0.9849\n",
      "Epoch 189/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0629 - accuracy: 0.9839\n",
      "Epoch 00189: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0637 - accuracy: 0.9839\n",
      "Epoch 190/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0711 - accuracy: 0.9808\n",
      "Epoch 00190: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0731 - accuracy: 0.9801\n",
      "Epoch 191/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0876 - accuracy: 0.9781\n",
      "Epoch 00191: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.9792\n",
      "Epoch 192/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0888 - accuracy: 0.9738\n",
      "Epoch 00192: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0902 - accuracy: 0.9735\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9678\n",
      "Epoch 00193: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1205 - accuracy: 0.9678\n",
      "Epoch 194/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0803 - accuracy: 0.9802\n",
      "Epoch 00194: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9782\n",
      "Epoch 195/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0677 - accuracy: 0.9839\n",
      "Epoch 00195: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0681 - accuracy: 0.9839\n",
      "Epoch 196/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9830\n",
      "Epoch 00196: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9830\n",
      "Epoch 197/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0755 - accuracy: 0.9771\n",
      "Epoch 00197: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0739 - accuracy: 0.9773\n",
      "Epoch 198/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0682 - accuracy: 0.9839\n",
      "Epoch 00198: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9839\n",
      "Epoch 199/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0647 - accuracy: 0.9829\n",
      "Epoch 00199: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0637 - accuracy: 0.9830\n",
      "Epoch 200/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0696 - accuracy: 0.9854\n",
      "Epoch 00200: loss did not improve from 0.06348\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0739 - accuracy: 0.9820\n",
      "Epoch 201/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0620 - accuracy: 0.9849\n",
      "Epoch 00201: loss improved from 0.06348 to 0.06180, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0618 - accuracy: 0.9849\n",
      "Epoch 202/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0648 - accuracy: 0.9844\n",
      "Epoch 00202: loss did not improve from 0.06180\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0666 - accuracy: 0.9830\n",
      "Epoch 203/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0618 - accuracy: 0.9839\n",
      "Epoch 00203: loss did not improve from 0.06180\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9839\n",
      "Epoch 204/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0591 - accuracy: 0.9859\n",
      "Epoch 00204: loss improved from 0.06180 to 0.06084, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.9849\n",
      "Epoch 205/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0809 - accuracy: 0.9781\n",
      "Epoch 00205: loss did not improve from 0.06084\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0846 - accuracy: 0.9773\n",
      "Epoch 206/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0833 - accuracy: 0.9768\n",
      "Epoch 00206: loss did not improve from 0.06084\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0810 - accuracy: 0.9782\n",
      "Epoch 207/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0695 - accuracy: 0.9812\n",
      "Epoch 00207: loss did not improve from 0.06084\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9820\n",
      "Epoch 208/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0672 - accuracy: 0.9829\n",
      "Epoch 00208: loss did not improve from 0.06084\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0683 - accuracy: 0.9820\n",
      "Epoch 209/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9839\n",
      "Epoch 00209: loss did not improve from 0.06084\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0657 - accuracy: 0.9839\n",
      "Epoch 210/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0652 - accuracy: 0.9819\n",
      "Epoch 00210: loss did not improve from 0.06084\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0636 - accuracy: 0.9820\n",
      "Epoch 211/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9848 ETA: 0s - loss: 0.0717 - accura\n",
      "Epoch 00211: loss improved from 0.06084 to 0.06022, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0602 - accuracy: 0.9849\n",
      "Epoch 212/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9839\n",
      "Epoch 00212: loss improved from 0.06022 to 0.05643, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0564 - accuracy: 0.9839\n",
      "Epoch 213/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.9839\n",
      "Epoch 00213: loss improved from 0.05643 to 0.05500, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0550 - accuracy: 0.9839\n",
      "Epoch 214/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0615 - accuracy: 0.9802\n",
      "Epoch 00214: loss did not improve from 0.05500\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0592 - accuracy: 0.9820\n",
      "Epoch 215/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0546 - accuracy: 0.9839\n",
      "Epoch 00215: loss improved from 0.05500 to 0.05459, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0546 - accuracy: 0.9839\n",
      "Epoch 216/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9839\n",
      "Epoch 00216: loss improved from 0.05459 to 0.05351, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0535 - accuracy: 0.9839\n",
      "Epoch 217/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0541 - accuracy: 0.9844\n",
      "Epoch 00217: loss improved from 0.05351 to 0.05251, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0525 - accuracy: 0.9858\n",
      "Epoch 218/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0497 - accuracy: 0.9859\n",
      "Epoch 00218: loss improved from 0.05251 to 0.05159, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0516 - accuracy: 0.9849\n",
      "Epoch 219/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9848\n",
      "Epoch 00219: loss did not improve from 0.05159\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0522 - accuracy: 0.9849\n",
      "Epoch 220/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0544 - accuracy: 0.9844\n",
      "Epoch 00220: loss did not improve from 0.05159\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0522 - accuracy: 0.9849\n",
      "Epoch 221/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0493 - accuracy: 0.98 - ETA: 0s - loss: 0.0498 - accuracy: 0.9859\n",
      "Epoch 00221: loss improved from 0.05159 to 0.05105, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0511 - accuracy: 0.9849\n",
      "Epoch 222/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9839\n",
      "Epoch 00222: loss improved from 0.05105 to 0.05081, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0508 - accuracy: 0.9839\n",
      "Epoch 223/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0500 - accuracy: 0.9854\n",
      "Epoch 00223: loss improved from 0.05081 to 0.05002, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0500 - accuracy: 0.9858\n",
      "Epoch 224/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0527 - accuracy: 0.9844\n",
      "Epoch 00224: loss did not improve from 0.05002\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0505 - accuracy: 0.9849\n",
      "Epoch 225/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0509 - accuracy: 0.9844\n",
      "Epoch 00225: loss improved from 0.05002 to 0.04939, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0494 - accuracy: 0.9849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9849\n",
      "Epoch 00226: loss improved from 0.04939 to 0.04862, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0486 - accuracy: 0.9849\n",
      "Epoch 227/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0483 - accuracy: 0.9879\n",
      "Epoch 00227: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 0.9858\n",
      "Epoch 228/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.9735\n",
      "Epoch 00228: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0801 - accuracy: 0.9735\n",
      "Epoch 229/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.9716\n",
      "Epoch 00229: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0969 - accuracy: 0.9716\n",
      "Epoch 230/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9688\n",
      "Epoch 00230: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0952 - accuracy: 0.9688\n",
      "Epoch 231/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9839\n",
      "Epoch 00231: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0702 - accuracy: 0.9839\n",
      "Epoch 232/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0652 - accuracy: 0.9802\n",
      "Epoch 00232: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0677 - accuracy: 0.9782\n",
      "Epoch 233/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0727 - accuracy: 0.9808\n",
      "Epoch 00233: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0706 - accuracy: 0.9811\n",
      "Epoch 234/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0794 - accuracy: 0.9740\n",
      "Epoch 00234: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9754\n",
      "Epoch 235/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9792\n",
      "Epoch 00235: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0669 - accuracy: 0.9792\n",
      "Epoch 236/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1065 - accuracy: 0.9678\n",
      "Epoch 00236: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1042 - accuracy: 0.9688\n",
      "Epoch 237/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9622\n",
      "Epoch 00237: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1200 - accuracy: 0.9622\n",
      "Epoch 238/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1001 - accuracy: 0.9698\n",
      "Epoch 00238: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.9716\n",
      "Epoch 239/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9801\n",
      "Epoch 00239: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0676 - accuracy: 0.9801\n",
      "Epoch 240/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0553 - accuracy: 0.9819\n",
      "Epoch 00240: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 0.0546 - accuracy: 0.9820\n",
      "Epoch 241/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0539 - accuracy: 0.9829\n",
      "Epoch 00241: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9830\n",
      "Epoch 242/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0436 - accuracy: 0.9885\n",
      "Epoch 00242: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0519 - accuracy: 0.9830\n",
      "Epoch 243/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0505 - accuracy: 0.9829\n",
      "Epoch 00243: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0529 - accuracy: 0.9811\n",
      "Epoch 244/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0552 - accuracy: 0.9792\n",
      "Epoch 00244: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0566 - accuracy: 0.9792\n",
      "Epoch 245/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0536 - accuracy: 0.9833\n",
      "Epoch 00245: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 0.9820\n",
      "Epoch 246/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0571 - accuracy: 0.9798\n",
      "Epoch 00246: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0570 - accuracy: 0.9801\n",
      "Epoch 247/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0528 - accuracy: 0.9812\n",
      "Epoch 00247: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0520 - accuracy: 0.9820\n",
      "Epoch 248/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0518 - accuracy: 0.9829\n",
      "Epoch 00248: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0512 - accuracy: 0.9839\n",
      "Epoch 249/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0526 - accuracy: 0.9833\n",
      "Epoch 00249: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0523 - accuracy: 0.9830\n",
      "Epoch 250/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9801\n",
      "Epoch 00250: loss did not improve from 0.04862\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0501 - accuracy: 0.9801\n",
      "Epoch 251/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0492 - accuracy: 0.9829\n",
      "Epoch 00251: loss improved from 0.04862 to 0.04731, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 0.0473 - accuracy: 0.9839\n",
      "Epoch 252/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9848\n",
      "Epoch 00252: loss improved from 0.04731 to 0.04581, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9849\n",
      "Epoch 253/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0450 - accuracy: 0.9869\n",
      "Epoch 00253: loss improved from 0.04581 to 0.04539, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0454 - accuracy: 0.9858\n",
      "Epoch 254/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9849\n",
      "Epoch 00254: loss improved from 0.04539 to 0.04506, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0451 - accuracy: 0.9849\n",
      "Epoch 255/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9820\n",
      "Epoch 00255: loss improved from 0.04506 to 0.04459, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0446 - accuracy: 0.9820\n",
      "Epoch 256/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9849\n",
      "Epoch 00256: loss did not improve from 0.04459\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.9849\n",
      "Epoch 257/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9839\n",
      "Epoch 00257: loss did not improve from 0.04459\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0446 - accuracy: 0.9839\n",
      "Epoch 258/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0434 - accuracy: 0.9873\n",
      "Epoch 00258: loss improved from 0.04459 to 0.04385, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.0439 - accuracy: 0.9868\n",
      "Epoch 259/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0427 - accuracy: 0.9839\n",
      "Epoch 00259: loss improved from 0.04385 to 0.04279, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0428 - accuracy: 0.9839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9867\n",
      "Epoch 00260: loss improved from 0.04279 to 0.04251, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0425 - accuracy: 0.9868\n",
      "Epoch 261/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9839\n",
      "Epoch 00261: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0433 - accuracy: 0.9839\n",
      "Epoch 262/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0527 - accuracy: 0.9808\n",
      "Epoch 00262: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0547 - accuracy: 0.9811\n",
      "Epoch 263/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0523 - accuracy: 0.9829\n",
      "Epoch 00263: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0519 - accuracy: 0.9830\n",
      "Epoch 264/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9830\n",
      "Epoch 00264: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0575 - accuracy: 0.9830\n",
      "Epoch 265/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1184 - accuracy: 0.9587\n",
      "Epoch 00265: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1162 - accuracy: 0.9584\n",
      "Epoch 266/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.4424 - accuracy: 0.8800\n",
      "Epoch 00266: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.4326 - accuracy: 0.8817\n",
      "Epoch 267/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9498\n",
      "Epoch 00267: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.1603 - accuracy: 0.9499\n",
      "Epoch 268/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1168 - accuracy: 0.9647\n",
      "Epoch 00268: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1195 - accuracy: 0.9631\n",
      "Epoch 269/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9659\n",
      "Epoch 00269: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9659\n",
      "Epoch 270/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0677 - accuracy: 0.9812\n",
      "Epoch 00270: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0647 - accuracy: 0.9830\n",
      "Epoch 271/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0572 - accuracy: 0.9829\n",
      "Epoch 00271: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0555 - accuracy: 0.9839\n",
      "Epoch 272/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0536 - accuracy: 0.9824\n",
      "Epoch 00272: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0526 - accuracy: 0.9830\n",
      "Epoch 273/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9839\n",
      "Epoch 00273: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0474 - accuracy: 0.9839\n",
      "Epoch 274/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0469 - accuracy: 0.9854\n",
      "Epoch 00274: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0459 - accuracy: 0.9858\n",
      "Epoch 275/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9858\n",
      "Epoch 00275: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.9858\n",
      "Epoch 276/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9858\n",
      "Epoch 00276: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0436 - accuracy: 0.9858\n",
      "Epoch 277/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0433 - accuracy: 0.9839\n",
      "Epoch 00277: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0432 - accuracy: 0.9849\n",
      "Epoch 278/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9849\n",
      "Epoch 00278: loss did not improve from 0.04251\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0426 - accuracy: 0.9849\n",
      "Epoch 279/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0430 - accuracy: 0.9833\n",
      "Epoch 00279: loss improved from 0.04251 to 0.04224, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0422 - accuracy: 0.9849\n",
      "Epoch 280/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9823\n",
      "Epoch 00280: loss did not improve from 0.04224\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0479 - accuracy: 0.9830\n",
      "Epoch 281/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0453 - accuracy: 0.9823\n",
      "Epoch 00281: loss did not improve from 0.04224\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.9839\n",
      "Epoch 282/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9858\n",
      "Epoch 00282: loss improved from 0.04224 to 0.04163, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0416 - accuracy: 0.9858\n",
      "Epoch 283/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9849\n",
      "Epoch 00283: loss improved from 0.04163 to 0.04131, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0413 - accuracy: 0.9849\n",
      "Epoch 284/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9868\n",
      "Epoch 00284: loss improved from 0.04131 to 0.04043, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0404 - accuracy: 0.9868\n",
      "Epoch 285/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0400 - accuracy: 0.9849\n",
      "Epoch 00285: loss improved from 0.04043 to 0.03985, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0398 - accuracy: 0.9858\n",
      "Epoch 286/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9858 ETA: 0s - loss: 0.0364 - accura\n",
      "Epoch 00286: loss did not improve from 0.03985\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.0403 - accuracy: 0.9858\n",
      "Epoch 287/300\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9848\n",
      "Epoch 00287: loss did not improve from 0.03985\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0400 - accuracy: 0.9849\n",
      "Epoch 288/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9849\n",
      "Epoch 00288: loss did not improve from 0.03985\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0404 - accuracy: 0.9849\n",
      "Epoch 289/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0386 - accuracy: 0.9869\n",
      "Epoch 00289: loss improved from 0.03985 to 0.03948, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9849\n",
      "Epoch 290/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0393 - accuracy: 0.9869\n",
      "Epoch 00290: loss improved from 0.03948 to 0.03894, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9868\n",
      "Epoch 291/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9858\n",
      "Epoch 00291: loss improved from 0.03894 to 0.03856, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0386 - accuracy: 0.9858\n",
      "Epoch 292/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0395 - accuracy: 0.9859\n",
      "Epoch 00292: loss did not improve from 0.03856\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9858\n",
      "Epoch 293/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0444 - accuracy: 0.9802\n",
      "Epoch 00293: loss did not improve from 0.03856\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0424 - accuracy: 0.9820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/300\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9849\n",
      "Epoch 00294: loss did not improve from 0.03856\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0428 - accuracy: 0.9849\n",
      "Epoch 295/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0387 - accuracy: 0.9844\n",
      "Epoch 00295: loss did not improve from 0.03856\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 0.9839\n",
      "Epoch 296/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0384 - accuracy: 0.9854\n",
      "Epoch 00296: loss did not improve from 0.03856\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9849\n",
      "Epoch 297/300\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0386 - accuracy: 0.9849\n",
      "Epoch 00297: loss improved from 0.03856 to 0.03829, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9849\n",
      "Epoch 298/300\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0380 - accuracy: 0.9863\n",
      "Epoch 00298: loss improved from 0.03829 to 0.03776, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9868\n",
      "Epoch 299/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0388 - accuracy: 0.9854\n",
      "Epoch 00299: loss improved from 0.03776 to 0.03729, saving model to model_py\\model.h5\n",
      "34/34 [==============================] - 0s 13ms/step - loss: 0.0373 - accuracy: 0.9858\n",
      "Epoch 300/300\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0388 - accuracy: 0.9844\n",
      "Epoch 00300: loss did not improve from 0.03729\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.0373 - accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "if train_model == True:\n",
    "    #créer le modèle\n",
    "    i = Input(shape=(input_shape,))\n",
    "    x = Embedding(vocabulary+1,10)(i)\n",
    "    #x = LSTM(10,return_sequences=True)(x)\n",
    "    x = Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10))(x)\n",
    "    x = Bidirectional(LSTM(10))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(output_length,activation=\"softmax\")(x)\n",
    "    model  = Model(i,x)\n",
    "\n",
    "    #compiler le modèle\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    #enregistrer le modèle à son meilleur résultat\n",
    "    model_name = \"model_py/model.h5\"\n",
    "\n",
    "    modelcheckpoint = ModelCheckpoint(model_name,\n",
    "                                      monitor='val_loss',\n",
    "                                      mode='auto',\n",
    "                                      verbose=1,\n",
    "                                      save_best_only=True)\n",
    "\n",
    "    callback_list = [modelcheckpoint]\n",
    "    \n",
    "    #entraîner le modèle\n",
    "    history = model.fit(x_train,y_train,epochs=300, validation_data=(x_val, y_val), callbacks=callback_list)\n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-phoenix",
   "metadata": {},
   "source": [
    "Faire une prédiction sur ``x_val`` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "color-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenir les arguments pour chaque ligne\n",
    "y_pred=model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "joined-branch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7,  4, 19,  9, 32,  3, 34, 23, 31, 12, 14, 27, 22,  0,  7, 28,\n",
       "       26, 20,  5, 22, 33, 33, 15,  5, 16, 20, 28,  8, 19,  1, 32,  0, 26,\n",
       "       22,  8, 15, 28, 11,  7, 34, 19, 16, 28, 19,  3, 34, 24, 26, 18, 16,\n",
       "       15,  6, 29, 33, 25, 34,  1,  9, 23, 22, 25,  1, 25, 17, 10, 15,  2,\n",
       "       28,  9,  0, 15,  4, 18,  6, 24, 33, 29, 24, 27,  8, 25, 26,  3, 35,\n",
       "       13, 26,  0, 19, 28, 23, 19, 31,  0,  8, 17,  2, 15,  7, 32,  1,  4,\n",
       "       14, 11,  2, 29, 28, 32,  7, 18, 32, 13, 16, 16, 16, 16,  8, 32,  7,\n",
       "       20,  5,  8, 11,  9, 11, 10,  1, 11, 26,  8, 19, 22, 12, 12, 23, 28,\n",
       "       23, 16,  8, 34,  8,  6,  2, 22,  4,  7, 23, 31, 22,  4,  0, 25, 34,\n",
       "       10,  5, 27, 22, 13, 15, 22, 29, 26, 17,  1, 35, 15, 12, 12,  6, 26,\n",
       "       22,  1,  6,  3,  8,  0, 29,  0,  8,  0,  0, 24, 22, 16, 10, 13, 12,\n",
       "        0, 19, 28,  1, 13,  0,  3, 34,  1, 13, 11, 11, 35, 22, 27,  1,  5,\n",
       "        1, 22, 15, 26, 17, 20,  8], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#récupérer l'argument maximal sur chaque ligne\n",
    "y_pred_2 =[]\n",
    "for pred in y_pred:\n",
    "    y_pred_2.append(pred.argmax())\n",
    "y_pred_2 = np.array(y_pred_2)\n",
    "y_pred_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-mercury",
   "metadata": {},
   "source": [
    "faire une matrice de confusion pour comparer y_train de y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "musical-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13cbb47c430>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAP+0lEQVR4nO3dbYxc1X3H8e8Pe20eDIKNsXFt2i3IrYpQs0ZbYx4SpSWkLopkeBGrVIp4gWJeBFGkVJVLUUMjvyBtSRreoBphxakoxUpAWBVKsFaJCMK4LNTYpk5DEm2JY2sXMK7tVvX64d8Xc7dazNzZebgPs3t+H2k1M2ce/ufOmB9n7pl7riICM0vXBXV3wMzq5RAwS5xDwCxxDgGzxDkEzBLnEDBLXC0hIGm9pP+Q9DNJm2uoPy5pv6S9ksYqqLdN0qSkAzPaBiXtkvROdnlFxfUfkfSr7D3YK+mOkmpfLemHkg5KelvSn2btlWx/i/pVbf+Fkv5V0ltZ/b/O2iv7/GcVEZX+AQuAnwPXAIuAt4DrKu7DOLC0wnqfBm4ADsxo+xtgc3Z9M/D1ius/AvxZBdu+Arghu34p8FPguqq2v0X9qrZfwJLs+gCwB1hX5ec/218dI4G1wM8i4hcRMQX8M7Chhn5UJiJeBo6e17wB2J5d3w7cWXH9SkTEkYh4M7t+AjgIrKSi7W9RvxLRcDK7OZD9BRV+/rOpIwRWAr+ccfsQFX4omQBekvSGpE0V1562PCKOQOMfKrCshj7cL2lf9nWh9OGopCFgDY3/G1a+/efVh4q2X9ICSXuBSWBXRNSy/XnqCAE1aav6t8u3RMQNwB8BX5b06Yrr94MngGuBYeAI8FiZxSQtAb4HPBgRx8us1Wb9yrY/Is5GxDCwClgr6fqyanWjjhA4BFw94/Yq4HCVHYiIw9nlJPA8ja8oVZuQtAIgu5yssnhETGT/OM8BT1LieyBpgMZ/gE9HxHNZc2Xb36x+lds/LSKOAT8C1lPz5z9THSHwOrBa0m9KWgT8MbCzquKSLpF06fR14HPAgdbPKsVO4J7s+j3AC1UWn/4HmLmLkt4DSQKeAg5GxDdm3FXJ9ufVr3D7r5R0eXb9IuCzwE+o+fP/iDr2RgJ30NhL+3PgLyuufQ2NGYm3gLerqA88Q2PIeZrGSOhe4BPAKPBOdjlYcf1/BPYD+2j8g1xRUu1baXzd2wfszf7uqGr7W9Svavt/F/i3rM4B4K+y9so+/9n+lHXIzBLlXwyaJc4hYJY4h4BZ4hwCZolzCJglrrYQqPHnuq7v+rXWr3vbz1fnSKDuN8L1XT/F2h/TUwjUvS6AmfWu6x8LSVpA41d/t9P4FdrrwN0R8e95z7l8cEFctWohAMc+OMfln2hk0OH9l+TXWbSoaXtMTXXV72mnOcUAi2d/4JKLmjZr6mzuU9rpW9v1S1JH/Zmf5dTZ/2HRgouB3j/LbtT5/tdR+3/5b6biVLOD91jYw+v+/7oAAJKm1wXIDYGrVi3kyZ2rPtb+tWtuyC2ycOWvN20/M/5uZ73t0rk1w03bFx3KPzy/qr7NNXV/linbE6O59/XydaAf1gUwsx71EgJtrQsgaZOkMUljxz4410M5MytDLyHQ1roAEbE1IkYiYmR6H4CZ9Y9edgwupLFj8DbgVzR2DP5JRLyd95zLNBg36raPtZ/cuC63zpIdr3XVP7N+s3Covn0ie2KU43G02B2DEXFG0v3AD2isILytVQCYWX/qZXaAiHgReLGgvphZDfwl3SxxDgGzxDkEzBLnEDBLXE87BjulRYua/nTU04CWgn79ebRHAmaJcwiYJc4hYJY4h4BZ4hwCZomrdHYgpqYK20M68cDNufctf/zVQmqYVeHcrcO5913wyt7S63skYJY4h4BZ4hwCZolzCJglziFgljiHgFni+uIAolbyphRbTQOOb7mpafvQw7s7qm3FqnONvX5WxTRgy/q1Vjez2jkEzBLnEDBLnEPALHEOAbPEdX0GIgBJ48AJ4CxwJiJGWj0+7wxEVfGsgfWjvFkTKG7mpJQzEM3w+xHxfgGvY2Y18NcBs8T1GgIBvCTpDUmbiuiQmVWr168Dt0TEYUnLgF2SfhIRL898QBYOmwAu5OIey5lZ0XoaCUTE4exyEngeWNvkMVsjYiQiRgZY3Es5MytB1yMBSZcAF0TEiez654CvFdazEuTNAuTNGrR6jqWtyD36dR870cvXgeXA85KmX+efIuL7hfTKzCrTdQhExC+ATxbYFzOrgacIzRLnEDBLnEPALHEOAbPEVbq8WDdaTcXk6XTKpdU0YN6Zjoo8y1HdZ6CxztU9rVckjwTMEucQMEucQ8AscQ4Bs8Q5BMwS19PyYp2qe3mxIv3g8N7c+/7w14Yr64dZO1otL+aRgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJ6/sDiPpVq2nAvAOCfDBQcYpc46+KMwD1M48EzBLnEDBLnEPALHEOAbPEOQTMEjfr7ICkbcDngcmIuD5rGwSeBYaAcWBjRHxYXjfnlrxZAM8adO7kxnVN25fseK2wGkXPAOTNNvTrTEM7I4FvA+vPa9sMjEbEamA0u21mc9CsIZCdZfjoec0bgO3Z9e3AncV2y8yq0u0+geURcQQgu1xWXJfMrEql/2JQ0iZgE8CFXFx2OTPrULcjgQlJKwCyy8m8B0bE1ogYiYiRARZ3Wc7MytLtSGAncA/waHb5QmE9msfyZgHGt9yU+5xWJ0YpStG/nS9y73iRswBV6ddZgDyzjgQkPQPsBn5b0iFJ99L4j/92Se8At2e3zWwOmnUkEBF359w1P1YMNUucfzFoljiHgFniHAJmiXMImCXOy4uVoNMpslbTgBMP3Ny0ffnjr3besRxFTgN2+3qd1plr03D9zCMBs8Q5BMwS5xAwS5xDwCxxDgGzxCkiKit2mQbjRvnXxkXImzWA/JmDqva0e49+/9kToxyPo2p2n0cCZolzCJglziFgljiHgFniHAJmiXMImCXOBxDNUa0OIMo709GZis505KnAucUjAbPEOQTMEucQMEucQ8AscQ4Bs8TNOjsgaRvweWAyIq7P2h4BvgS8lz3soYh4saxOWmfyznR06Y+XNm3/r79Y1fFr2fzRzkjg28D6Ju3fjIjh7M8BYDZHzRoCEfEycLSCvphZDXrZJ3C/pH2Stkm6orAemVmlug2BJ4BrgWHgCPBY3gMlbZI0JmnsNKe6LGdmZekqBCJiIiLORsQ54ElgbYvHbo2IkYgYGWBxt/00s5J0deyApBURcSS7eRdwoLguzX39urzWiU+937T93S2rc58z9EpZvbF+0c4U4TPAZ4Clkg4BXwU+I2kYCGAcuK+8LppZmWYNgYi4u0nzUyX0xcxq4F8MmiXOIWCWOIeAWeIcAmaJ64vlxfKWw4K5eQBL3VOBnRp6eHfufSc3rmvavmTHa7nPKXKKtF+nW+cTjwTMEucQMEucQ8AscQ4Bs8Q5BMwSp4iorNhlGowbdVtl9eaDft07Pt9mdOa7PTHK8TiqZvd5JGCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4vriACLLV/dUYJ5W04DjW25q2t7qQCWrj0cCZolzCJglziFgljiHgFniHAJmiWvn5CNXA98BrgLOAVsj4luSBoFngSEaJyDZGBEfltdVq0M3BzDlzQJ081p5Byp1c5BS3QdjVbHsWjev185I4AzwlYj4HWAd8GVJ1wGbgdGIWA2MZrfNbI6ZNQQi4khEvJldPwEcBFYCG4Dt2cO2A3eW1EczK1FH+wQkDQFrgD3A8umTkmaXywrvnZmVru0QkLQE+B7wYEQc7+B5mySNSRo7zalu+mhmJWorBCQN0AiApyPiuax5QtKK7P4VwGSz50bE1ogYiYiRARYX0WczK9Csy4tJEo3v/Ecj4sEZ7X8LfBARj0raDAxGxJ+3eq285cW8VJVZuVotL9bOAUS3AF8E9kvam7U9BDwK7JB0L/Au8IUC+mpmFZs1BCLiFaBpggBeNdRsjvMvBs0S5xAwS5xDwCxxDgGzxPXF8mKeBrQ882mpsroPYMrjkYBZ4hwCZolzCJglziFgljiHgFni+mJ2wCxP3ixA3qxBq+fUre5ZgDweCZglziFgljiHgFniHAJmiXMImCXOIWCWOE8R9rl+PeikKnnb32oacOKBm5u2r9x5qGl7Ku9lHo8EzBLnEDBLnEPALHEOAbPEOQTMEjfr7ICkq4HvAFcB54CtEfEtSY8AXwLeyx76UES8WFZH54O8My21Wl4tb891Kmdt6mbP/fLHX23aPpX3/s/B2YG8WRPo/D1rZ4rwDPCViHhT0qXAG5J2Zfd9MyL+rqOKZtZX2jkD0RFg+hTkJyQdBFaW3TEzq0ZH+wQkDQFrgD1Z0/2S9knaJumKojtnZuVrOwQkLaFxevIHI+I48ARwLTBMY6TwWM7zNkkakzR2mlO999jMCtVWCEgaoBEAT0fEcwARMRERZyPiHPAksLbZcyNia0SMRMTIAIuL6reZFaSd2QEBTwEHI+IbM9pXZPsLAO4CDpTTxfmjyL32Rb5WkXua+1nee/bTf/i93Of81n2vl9Sb3hT5ubQzO3AL8EVgv6S9WdtDwN2ShoEAxoH7CuuVmVWmndmBVwA1ucu/CTCbB/yLQbPEOQTMEucQMEucQ8AscV5ezObVNGA3Wk0D5i1VlneQ0lzkkYBZ4hwCZolzCJglziFgljiHgFniPDtg1kLeLMClP16a+5wTn3q/sPpVnHzGIwGzxDkEzBLnEDBLnEPALHEOAbPEOQTMEtcXU4SprHFn80eracCTG9c1bV+y47WO61Tx798jAbPEOQTMEucQMEucQ8AscQ4Bs8S1cwaiC4GXgcXZ478bEV+VNAg8CwzROPnIxoj4sJtOTK0azL1vLp473tLWzSxAndoZCZwC/iAiPknj5KPrJa0DNgOjEbEaGM1um9kcM2sIRMPJ7OZA9hfABmB71r4duLOMDppZudo9K/GC7DyEk8CuiNgDLJ8+IWl2uay0XppZadoKgewU5MPAKmCtpOvbLSBpk6QxSWOnOdVlN82sLB3NDkTEMeBHwHpgQtIKaJymnMYoodlztkbESESMDLC4t96aWeHamR24EjgdEcckXQR8Fvg6sBO4B3g0u3yh207knTceqlleyaxOeccaQDUzDe0cQLQC2C5pAY2Rw46I+BdJu4Edku4F3gW+UGI/zawks4ZAROwD1jRp/wC4rYxOmVl1/ItBs8Q5BMwS5xAwS5xDwCxxXl5sFp6itLK1mgYscqmyPB4JmCXOIWCWOIeAWeIcAmaJcwiYJa4vZgda7Wmve++8ZwGKU/dnWVX9IuvkzQKMb7kp9zlDD+/uqIZHAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglThFRWbHLNBg3yosRWX85d+tw7n2t1r/sV80OOtr/0t9z8ugv1ezxHgmYJc4hYJY4h4BZ4hwCZolzCJglrtLZAUnvAf+Z3VwKvF9Z8Y9zfdevq34dtX8jIq5sdkelIfCRwtJYRIzUUtz1Xb/G+nVv+/n8dcAscQ4Bs8TVGQJba6zt+q5fZ/26t/0jatsnYGb9wV8HzBLnEDBLnEPALHEOAbPEOQTMEvd/uLAS3iuPEqYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix( y_val , y_pred_2)\n",
    "plt.matshow(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-tattoo",
   "metadata": {},
   "source": [
    "### Historique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "colored-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if train_model == True:\n",
    "    #montrer l'historique de précision et des pertes\n",
    "    plt.plot(history.history['accuracy'],label=\"précision de l'entraînement\")\n",
    "    plt.plot(history.history['loss'],label=\"pertes de l'entraînement\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "trained-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model == False:\n",
    "    model = load_model(\"model_py/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-principal",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Taper 0 pour sortir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "grateful-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous : Bonjour.\n",
      "bonjour 0 francais\n",
      "[[ 0  0  0  0  0  0  0 48  3  1]]\n",
      "34\n",
      "salutation\n",
      "Vous : Je suis partenaire.\n",
      "partenair 0 francais\n",
      "[[ 0  0  0  0  0  0  0 16  3  1]]\n",
      "32\n",
      "partenaire\n",
      "Vous : Quand commence la formation ?\n",
      "quand commenc format ? francais\n",
      "[[  0   0   0   0   0   0  61 156   4   1]]\n",
      "7\n",
      "date\n",
      "Vous : 0\n"
     ]
    }
   ],
   "source": [
    "if test == True:\n",
    "    while True:\n",
    "      texts_p = []\n",
    "      prediction_input = input('Vous : ')\n",
    "      if prediction_input == \"0\":\n",
    "        break\n",
    "\n",
    "      #appliquer la fonction treatment\n",
    "      prediction_input = treatment(prediction_input)\n",
    "      texts_p.append(prediction_input)\n",
    "      print(prediction_input)\n",
    "\n",
    "      #tokenizer et padding\n",
    "      prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "      prediction_input = np.array(prediction_input).reshape(-1)\n",
    "      prediction_input = pad_sequences([prediction_input],input_shape)\n",
    "      print(prediction_input)\n",
    "\n",
    "      #obtenir la prédiction du modèle\n",
    "      output = model.predict(prediction_input)\n",
    "      output = output.argmax()\n",
    "      print(output)\n",
    "\n",
    "      #trouver la tag correspondante et la réponse\n",
    "      response_tag = le.inverse_transform([output])[0]\n",
    "      print(response_tag)\n",
    "      #print(\"Chatbot : \",random.choice(responses[response_tag]))\n",
    "      if response_tag == \"goodbye\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-liabilities",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "differential-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "if api == True:\n",
    "    app = Flask(__name__)\n",
    "\n",
    "    s_list = [\"inconnu\", \"apprenant\", \"partenaire\"]\n",
    "    user_status = s_list[0]\n",
    "\n",
    "    #créer deux listes de tags identifiant l'utilisateur comme étant apprenant ou partenaire\n",
    "    appr_list = []\n",
    "    part_list = []\n",
    "\n",
    "    #créer deux dictionnaires avec les équivalents d'output apprenant/partenaire\n",
    "    to_appr = {}\n",
    "    to_part = {}\n",
    "\n",
    "\n",
    "    #definir les app.route\n",
    "    @app.route(\"/\")\n",
    "    def index():\n",
    "        return render_template(\"index.html\")\n",
    "\n",
    "    @app.route(\"/get\")\n",
    "    #fonction de réponse\n",
    "    def get_bot_response():\n",
    "        #obtenir la question et la formatter\n",
    "        texts_p = []\n",
    "        prediction_input = request.args.get('msg')\n",
    "        prediction_input = treatment(prediction_input)\n",
    "        texts_p.append(prediction_input)\n",
    "\n",
    "        #formatter l'input\n",
    "        prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "        prediction_input = np.array(prediction_input).reshape(-1)\n",
    "        prediction_input = pad_sequences([prediction_input],input_shape)\n",
    "\n",
    "        #prédire l'output\n",
    "        output = model.predict(prediction_input)\n",
    "        output = output.argmax()\n",
    "\n",
    "        #vérifier si l'output identifie l'utilisateur\n",
    "        if output in appr_list:\n",
    "            user_status = s_list[1]\n",
    "        elif output in part_list:\n",
    "            user_status = s_list[2]\n",
    "\n",
    "        #si l'utilisateur est identifié et l'output est susceptible de changer pour ça, alors le changer\n",
    "        if user_status == s_list[1] and output in to_appr.keys():\n",
    "            output = to_appr[output]\n",
    "        elif user_status == s_list[2] and output in to_part.keys():\n",
    "            output = to_part[output]\n",
    "\n",
    "        #transformer la réponse et la renvoyer\n",
    "        response_tag = le.inverse_transform([output])[0]\n",
    "        response = str(\"Chatbot : \",random.choice(responses[response_tag]))\n",
    "        return response\n",
    "\n",
    "    #lancer l'API\n",
    "    if __name__ == \"__main__\":\n",
    "        app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
